{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb5f812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                open      high       low     close  volume\n",
      "date                                                      \n",
      "2024-05-02  22567.85  22710.50  22567.85  22648.20       0\n",
      "2024-05-03  22766.35  22794.70  22348.05  22475.85       0\n",
      "2024-05-06  22561.60  22588.80  22409.45  22442.70       0\n",
      "2024-05-07  22489.75  22499.05  22232.05  22302.50       0\n",
      "2024-05-08  22231.20  22368.65  22185.20  22302.50       0\n",
      "...              ...       ...       ...       ...     ...\n",
      "2025-04-24  24277.90  24347.85  24216.15  24246.70       0\n",
      "2025-04-25  24289.00  24365.45  23847.85  24039.35       0\n",
      "2025-04-28  24070.25  24355.10  24054.05  24328.50       0\n",
      "2025-04-29  24370.70  24457.65  24290.75  24335.95       0\n",
      "2025-04-30  24342.05  24396.15  24198.75  24334.20       0\n",
      "\n",
      "[248 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from fyers_apiv3 import fyersModel\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Initialize the Fyers API client\n",
    "access_token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsiZDoxIiwiZDoyIiwieDowIiwieDoxIiwieDoyIl0sImF0X2hhc2giOiJnQUFBQUFCb1BvbHVaaHMxYXdwZjR1eUlPcnFjQTFfQVNzbzlDSXMxYTExdzQ2akZMbDBNSjlJSXhmUmE3THEzT0xmSVl2XzZZY1RTZFNQMkd0N2pYV0daUEpMaXpTamR6SEFJRkpGcEd2TFBVWmdQZXBiYXN6cz0iLCJkaXNwbGF5X25hbWUiOiIiLCJvbXMiOiJLMSIsImhzbV9rZXkiOiIzNzJmNjg5NTlmYWQ2NDBkOGEyMmQ3NTEzMWU3ODk0ZjE3MDViYWU5MzNkNjYzMzE3MjY5NjNmZiIsImlzRGRwaUVuYWJsZWQiOiJOIiwiaXNNdGZFbmFibGVkIjoiTiIsImZ5X2lkIjoiWUE0NzM3MyIsImFwcFR5cGUiOjEwMCwiZXhwIjoxNzQ4OTk3MDAwLCJpYXQiOjE3NDg5Mjg4NzgsImlzcyI6ImFwaS5meWVycy5pbiIsIm5iZiI6MTc0ODkyODg3OCwic3ViIjoiYWNjZXNzX3Rva2VuIn0.R3-UNkIX_29uCijSiwbVtSPoLGsJju21Bs4T5uo10Zs\"  # or your existing token\n",
    "client_id = \"FYZT8L00T9-100\"\n",
    "fyers = fyersModel.FyersModel(client_id=client_id, token=access_token)\n",
    "\n",
    "def fetch_historical_data(symbol, start_date, end_date, interval=\"D\"):\n",
    "    data = {\n",
    "        \"symbol\": symbol,\n",
    "        \"resolution\": interval,\n",
    "        \"date_format\": \"1\",  # Use \"1\" for string dates\n",
    "        \"range_from\": start_date,\n",
    "        \"range_to\": end_date,\n",
    "        \"cont_flag\": \"1\"\n",
    "    }\n",
    "    response = fyers.history(data)\n",
    "    if response['s'] == 'ok':\n",
    "        df = pd.DataFrame(response['candles'], columns=['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "        df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "        df.set_index('date', inplace=True)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Error fetching data:\", response)\n",
    "        return None\n",
    "\n",
    "# Define the symbol and date range\n",
    "symbol = \"NSE:NIFTY50-INDEX\"\n",
    "start_date = \"2024-05-01\"\n",
    "end_date = \"2025-04-30\"\n",
    "\n",
    "# Fetch the data\n",
    "df = fetch_historical_data(symbol, start_date, end_date)\n",
    "if df is not None:\n",
    "    #print(df.head())\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9469ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from 2024-05-05 to 2025-04-30\n",
      "Error fetching data: {'code': -16, 'message': 'Could not authenticate the user', 's': 'error'}\n",
      "Fetching data from 2024-05-05 to 2025-04-30\n",
      "Error fetching data: {'code': -16, 'message': 'Could not authenticate the user', 's': 'error'}\n"
     ]
    }
   ],
   "source": [
    "def fetch_historical_data(symbol, start_date_str, end_date_str, interval=\"D\"):\n",
    "    import datetime\n",
    "    all_candles = []\n",
    "    \n",
    "    # Convert string dates to datetime objects\n",
    "    current_end_date = datetime.datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "    overall_start_date = datetime.datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    while current_end_date >= overall_start_date:\n",
    "        # Calculate the start date for the current chunk\n",
    "        chunk_start_date = current_end_date - datetime.timedelta(days=360)\n",
    "        \n",
    "        # Ensure the chunk_start_date does not go before the overall_start_date\n",
    "        if chunk_start_date < overall_start_date:\n",
    "            chunk_start_date = overall_start_date\n",
    "\n",
    "        data = {\n",
    "            \"symbol\": symbol,\n",
    "            \"resolution\": interval,\n",
    "            \"date_format\": \"1\",\n",
    "            \"range_from\": chunk_start_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"range_to\": current_end_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"cont_flag\": \"1\"\n",
    "        }\n",
    "        \n",
    "        print(f\"Fetching data from {data['range_from']} to {data['range_to']}\")\n",
    "        response = fyers.history(data)\n",
    "\n",
    "        if response['s'] == 'ok' and response.get('candles'):\n",
    "            all_candles.extend(response['candles'])\n",
    "        elif response['s'] == 'no_data':\n",
    "            print(f\"No data found for range: {data['range_from']} to {data['range_to']}\")\n",
    "            break \n",
    "        else:\n",
    "            print(\"Error fetching data:\", response)\n",
    "            return None\n",
    "        \n",
    "        current_end_date = chunk_start_date - datetime.timedelta(days=1)\n",
    "        \n",
    "        if chunk_start_date == overall_start_date and current_end_date < overall_start_date:\n",
    "            break \n",
    "\n",
    "    if not all_candles:\n",
    "        print(\"No historical data fetched after multiple attempts.\")\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(all_candles, columns=['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "    df.set_index('date', inplace=True)\n",
    "    df = df.sort_index()\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    df = df.loc[start_date_str:end_date_str]\n",
    "\n",
    "    return df\n",
    "\n",
    "# The existing symbol, start_date, and end_date variables can be used directly\n",
    "df = fetch_historical_data(symbol, start_date, end_date)\n",
    "if df is not None:\n",
    "    print(df)\n",
    "\n",
    "# Define the symbol and date range\n",
    "symbol = \"NSE:NIFTY50-INDEX\"\n",
    "start_date = \"2022-05-01\"\n",
    "end_date = \"2025-04-30\"\n",
    "\n",
    "# Fetch the data\n",
    "df = fetch_historical_data(symbol, start_date, end_date)\n",
    "if df is not None:\n",
    "    #print(df.head())\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb19f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to fetch data for 'NSE:NIFTY50-INDEX' from year 2021 up to 2025-04-30 (covering 4 prior full year(s) plus current year portion).\n",
      "Fetching data for 'NSE:NIFTY50-INDEX' from 2021-01-01 to 2021-12-31\n",
      "  Successfully fetched 248 candles for 2021-01-01 to 2021-12-31.\n",
      "Fetching data for 'NSE:NIFTY50-INDEX' from 2022-01-01 to 2022-12-31\n",
      "  Successfully fetched 248 candles for 2022-01-01 to 2022-12-31.\n",
      "Fetching data for 'NSE:NIFTY50-INDEX' from 2023-01-01 to 2023-12-31\n",
      "  Successfully fetched 246 candles for 2023-01-01 to 2023-12-31.\n",
      "Fetching data for 'NSE:NIFTY50-INDEX' from 2024-01-01 to 2024-12-31\n",
      "  Successfully fetched 249 candles for 2024-01-01 to 2024-12-31.\n",
      "Fetching data for 'NSE:NIFTY50-INDEX' from 2025-01-01 to 2025-04-30\n",
      "  Successfully fetched 81 candles for 2025-01-01 to 2025-04-30.\n",
      "Successfully processed data for 'NSE:NIFTY50-INDEX'. Total records: 1072. Date range in DataFrame: 2021-01-01 00:00:00 to 2025-04-30 00:00:00\n",
      "                open      high       low     close  volume\n",
      "date                                                      \n",
      "2021-01-01  13996.10  14049.80  13991.30  14018.50       0\n",
      "2021-01-04  14104.30  14148.00  13953.80  14132.90       0\n",
      "2021-01-05  14075.20  14215.60  14048.20  14199.50       0\n",
      "2021-01-06  14241.00  14244.20  14039.90  14146.20       0\n",
      "2021-01-07  14253.80  14256.20  14123.10  14137.30       0\n",
      "...              ...       ...       ...       ...     ...\n",
      "2025-04-24  24277.90  24347.85  24216.15  24246.70       0\n",
      "2025-04-25  24289.00  24365.45  23847.85  24039.35       0\n",
      "2025-04-28  24070.25  24355.10  24054.05  24328.50       0\n",
      "2025-04-29  24370.70  24457.65  24290.75  24335.95       0\n",
      "2025-04-30  24342.05  24396.15  24198.75  24334.20       0\n",
      "\n",
      "[1072 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import calendar\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_historical_data(symbol: str, end_date_str: str, years_of_data: int, interval: str = \"D\"):\n",
    "    \"\"\"\n",
    "    Fetches historical data for a symbol for a specified number of years ending on end_date_str.\n",
    "    Data is fetched year by year.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): The trading symbol (e.g., \"NSE:NIFTY50-INDEX\").\n",
    "        end_date_str (str): The end date for the data in \"YYYY-MM-DD\" format.\n",
    "        years_of_data (int): The number of past full years of data to fetch, plus the current year up to end_date.\n",
    "                             Example: end_date_str=\"2025-04-30\", years_of_data=4 means data from\n",
    "                             2021-01-01 to 2021-12-31, ..., 2024-01-01 to 2024-12-31, \n",
    "                             and 2025-01-01 to 2025-04-30.\n",
    "        interval (str): The data interval (e.g., \"D\" for daily).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the historical data, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    #access_token = get_token()\n",
    "    # The fyersModel should be imported. It might be fyersModel.FyersModel or similar\n",
    "    # depending on the library version.\n",
    "    #fyers = fyersModel(client_id=client_id, token=access_token)\n",
    "    all_candles = []\n",
    "\n",
    "    try:\n",
    "        target_end_date_obj = datetime.datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        print(f\"Error: Invalid end_date_str format. Please use YYYY-MM-DD. Got: {end_date_str}\")\n",
    "        return None\n",
    "\n",
    "    if not isinstance(years_of_data, int) or years_of_data < 0: # Allow 0 for current year only\n",
    "        print(\"Error: years_of_data must be a non-negative integer.\")\n",
    "        return None\n",
    "\n",
    "    # Calculate the range of years to fetch\n",
    "    # If years_of_data = 4 and end_date is 2025-04-30, we fetch for 2021, 2022, 2023, 2024, and part of 2025.\n",
    "    # The first year in the iteration will be target_end_date_obj.year - years_of_data.\n",
    "    first_year_to_fetch = target_end_date_obj.year - years_of_data\n",
    "    last_year_to_fetch = target_end_date_obj.year # This is the year of the end_date_str\n",
    "\n",
    "    print(f\"Preparing to fetch data for '{symbol}' from year {first_year_to_fetch} up to {end_date_str} (covering {years_of_data} prior full year(s) plus current year portion).\")\n",
    "\n",
    "    for year_iter in range(first_year_to_fetch, last_year_to_fetch + 1):\n",
    "        current_chunk_start_date_str = f\"{year_iter}-01-01\"\n",
    "        \n",
    "        if year_iter < last_year_to_fetch:\n",
    "            # For full years before the target_end_date_obj's year\n",
    "            current_chunk_end_date_str = f\"{year_iter}-12-31\"\n",
    "        else:\n",
    "            # For the final year (which is target_end_date_obj.year), fetch up to target_end_date_obj\n",
    "            current_chunk_end_date_str = target_end_date_obj.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        # Ensure the chunk_start_date is not later than chunk_end_date.\n",
    "        if datetime.datetime.strptime(current_chunk_start_date_str, \"%Y-%m-%d\") > datetime.datetime.strptime(current_chunk_end_date_str, \"%Y-%m-%d\"):\n",
    "            print(f\"  Skipping data fetch for year {year_iter}: chunk start date {current_chunk_start_date_str} is after chunk end date {current_chunk_end_date_str}.\")\n",
    "            continue\n",
    "\n",
    "        payload = {\n",
    "            \"symbol\": symbol,\n",
    "            \"resolution\": interval,\n",
    "            \"date_format\": \"1\",  # \"1\" for epoch timestamp in response\n",
    "            \"range_from\": current_chunk_start_date_str,\n",
    "            \"range_to\": current_chunk_end_date_str,\n",
    "            \"cont_flag\": \"1\"     # For continuous data for expired futures\n",
    "        }\n",
    "        \n",
    "        print(f\"Fetching data for '{symbol}' from {payload['range_from']} to {payload['range_to']}\")\n",
    "        response = fyers.history(data=payload) # Pass payload with keyword 'data='\n",
    "\n",
    "        if response and response.get('s') == 'ok':\n",
    "            if response.get('candles'):\n",
    "                all_candles.extend(response['candles'])\n",
    "                print(f\"  Successfully fetched {len(response['candles'])} candles for {payload['range_from']} to {payload['range_to']}.\")\n",
    "            else:\n",
    "                print(f\"  No data in 'candles' (s='ok') for range: {payload['range_from']} to {payload['range_to']}.\")\n",
    "        elif response and response.get('s') == 'no_data':\n",
    "            print(f\"  API reported no data (s='no_data') for range: {payload['range_from']} to {payload['range_to']}. Message: {response.get('message')}\")\n",
    "        else:\n",
    "            error_message = response.get('message', 'Unknown error') if response else \"No response or malformed response from API\"\n",
    "            print(f\"  Error fetching data for range {payload['range_from']} to {payload['range_to']}: {error_message}\")\n",
    "            # print(f\"  Full response for error: {response}\") # Uncomment for detailed debugging\n",
    "            return None # Fail fast if any chunk results in an error\n",
    "        \n",
    "    if not all_candles:\n",
    "        print(f\"No historical data was fetched for '{symbol}' after all attempts for the period ending {end_date_str} covering {years_of_data} prior year(s).\")\n",
    "        return pd.DataFrame(columns=['open', 'high', 'low', 'close', 'volume']).set_index(pd.to_datetime([]))\n",
    "\n",
    "\n",
    "    # Convert all collected candles to a DataFrame\n",
    "    df = pd.DataFrame(all_candles, columns=['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    \n",
    "    # Convert 'date' from epoch timestamp to datetime objects\n",
    "    df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Sort by date as data from chunks might not be perfectly ordered\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # Remove duplicate dates if any\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    \n",
    "    # Filter to ensure data is within the *overall* requested date range.\n",
    "    # The overall_start_date is January 1st of the first_year_to_fetch.\n",
    "    # The overall_end_date is the target_end_date_obj.\n",
    "    overall_start_date_for_filter = datetime.datetime(first_year_to_fetch, 1, 1)\n",
    "    \n",
    "    # Apply the precise range filtering. Pandas slicing with datetime index includes both start and end.\n",
    "    df = df.loc[overall_start_date_for_filter : target_end_date_obj]\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"Dataframe is empty after processing for '{symbol}' ending {end_date_str} (requested {years_of_data} prior years).\")\n",
    "    else:\n",
    "        print(f\"Successfully processed data for '{symbol}'. Total records: {len(df)}. Date range in DataFrame: {df.index.min()} to {df.index.max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assume fyers and related initialization from your earlier code are already done.\n",
    "symbol = \"NSE:NIFTY50-INDEX\"\n",
    "end_date = \"2025-04-30\"\n",
    "years_of_data = 4  # Fetch last 4 years (full years plus partial current year)\n",
    "\n",
    "df = fetch_historical_data(symbol, end_date, years_of_data, interval=\"D\")\n",
    "if df is not None:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44529c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_historical_data(symbol, start_date_str, end_date_str, interval=\"D\"):\n",
    "    import datetime\n",
    "    all_candles = []\n",
    "    \n",
    "    # Convert string dates to datetime objects\n",
    "    current_end_date = datetime.datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "    overall_start_date = datetime.datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    while current_end_date >= overall_start_date:\n",
    "        # Calculate the start date for the current chunk: go back 360 days\n",
    "        chunk_start_date = current_end_date - datetime.timedelta(days=360)\n",
    "        \n",
    "        # Ensure the chunk_start_date does not go before the overall_start_date\n",
    "        if chunk_start_date < overall_start_date:\n",
    "            chunk_start_date = overall_start_date\n",
    "\n",
    "        data = {\n",
    "            \"symbol\": symbol,\n",
    "            \"resolution\": interval,\n",
    "            \"date_format\": \"1\",  # Use \"1\" for string dates\n",
    "            \"range_from\": chunk_start_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"range_to\": current_end_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"cont_flag\": \"1\"\n",
    "        }\n",
    "        \n",
    "        print(f\"Fetching data from {data['range_from']} to {data['range_to']}\")\n",
    "        response = fyers.history(data)\n",
    "\n",
    "        if response['s'] == 'ok' and response.get('candles'):\n",
    "            all_candles.extend(response['candles'])\n",
    "        elif response['s'] == 'no_data':\n",
    "            print(f\"No data found for range: {data['range_from']} to {data['range_to']}\")\n",
    "            break \n",
    "        else:\n",
    "            print(\"Error fetching data:\", response)\n",
    "            return None\n",
    "        \n",
    "        # Set the end date for the next iteration to be one day before the current chunk's start date\n",
    "        current_end_date = chunk_start_date - datetime.timedelta(days=1)\n",
    "        \n",
    "        # Safeguard to avoid infinite loops\n",
    "        if chunk_start_date == overall_start_date and current_end_date < overall_start_date:\n",
    "            break \n",
    "\n",
    "    if not all_candles:\n",
    "        print(\"No historical data fetched after multiple attempts.\")\n",
    "        return None\n",
    "\n",
    "    # Convert all collected candles to a DataFrame\n",
    "    df = pd.DataFrame(all_candles, columns=['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Sort by date in ascending order\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # Remove duplicate dates if any\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    \n",
    "    # Filter to include only the requested date range\n",
    "    df = df.loc[start_date_str:end_date_str]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Define the symbol and date range:\n",
    "symbol = \"NSE:NIFTY50-INDEX\"\n",
    "start_date = \"2024-05-01\"\n",
    "end_date = \"2025-04-30\"\n",
    "\n",
    "# Fetch the data:\n",
    "df = fetch_historical_data(symbol, start_date, end_date)\n",
    "if df is not None:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72452e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Percentage Returns with Calculation Steps:\n",
      "\n",
      "2025-01-02:\t((24188.65 - 23742.90) / 23742.90) * 100 = 1.8774%\n",
      "2025-01-03:\t((24004.75 - 24188.65) / 24188.65) * 100 = -0.7603%\n",
      "2025-01-06:\t((23616.05 - 24004.75) / 24004.75) * 100 = -1.6193%\n",
      "2025-01-07:\t((23707.90 - 23616.05) / 23616.05) * 100 = 0.3889%\n",
      "2025-01-08:\t((23688.95 - 23707.90) / 23707.90) * 100 = -0.0799%\n",
      "2025-01-09:\t((23526.50 - 23688.95) / 23688.95) * 100 = -0.6858%\n",
      "2025-01-10:\t((23431.50 - 23526.50) / 23526.50) * 100 = -0.4038%\n",
      "2025-01-13:\t((23085.95 - 23431.50) / 23431.50) * 100 = -1.4747%\n",
      "2025-01-14:\t((23176.05 - 23085.95) / 23085.95) * 100 = 0.3903%\n",
      "2025-01-15:\t((23213.20 - 23176.05) / 23176.05) * 100 = 0.1603%\n",
      "2025-01-16:\t((23311.80 - 23213.20) / 23213.20) * 100 = 0.4248%\n",
      "2025-01-17:\t((23203.20 - 23311.80) / 23311.80) * 100 = -0.4659%\n",
      "2025-01-20:\t((23344.75 - 23203.20) / 23203.20) * 100 = 0.6100%\n",
      "2025-01-21:\t((23024.65 - 23344.75) / 23344.75) * 100 = -1.3712%\n",
      "2025-01-22:\t((23155.35 - 23024.65) / 23024.65) * 100 = 0.5677%\n",
      "2025-01-23:\t((23205.35 - 23155.35) / 23155.35) * 100 = 0.2159%\n",
      "2025-01-24:\t((23092.20 - 23205.35) / 23205.35) * 100 = -0.4876%\n",
      "2025-01-27:\t((22829.15 - 23092.20) / 23092.20) * 100 = -1.1391%\n",
      "2025-01-28:\t((22957.25 - 22829.15) / 22829.15) * 100 = 0.5611%\n",
      "2025-01-29:\t((23163.10 - 22957.25) / 22957.25) * 100 = 0.8967%\n",
      "2025-01-30:\t((23249.50 - 23163.10) / 23163.10) * 100 = 0.3730%\n",
      "2025-01-31:\t((23508.40 - 23249.50) / 23249.50) * 100 = 1.1136%\n",
      "2025-02-01:\t((23482.15 - 23508.40) / 23508.40) * 100 = -0.1117%\n",
      "2025-02-03:\t((23361.05 - 23482.15) / 23482.15) * 100 = -0.5157%\n",
      "2025-02-04:\t((23739.25 - 23361.05) / 23361.05) * 100 = 1.6189%\n",
      "2025-02-05:\t((23696.30 - 23739.25) / 23739.25) * 100 = -0.1809%\n",
      "2025-02-06:\t((23603.35 - 23696.30) / 23696.30) * 100 = -0.3923%\n",
      "2025-02-07:\t((23559.95 - 23603.35) / 23603.35) * 100 = -0.1839%\n",
      "2025-02-10:\t((23381.60 - 23559.95) / 23559.95) * 100 = -0.7570%\n",
      "2025-02-11:\t((23071.80 - 23381.60) / 23381.60) * 100 = -1.3250%\n",
      "2025-02-12:\t((23045.25 - 23071.80) / 23071.80) * 100 = -0.1151%\n",
      "2025-02-13:\t((23031.40 - 23045.25) / 23045.25) * 100 = -0.0601%\n",
      "2025-02-14:\t((22929.25 - 23031.40) / 23031.40) * 100 = -0.4435%\n",
      "2025-02-17:\t((22959.50 - 22929.25) / 22929.25) * 100 = 0.1319%\n",
      "2025-02-18:\t((22945.30 - 22959.50) / 22959.50) * 100 = -0.0618%\n",
      "2025-02-19:\t((22932.90 - 22945.30) / 22945.30) * 100 = -0.0540%\n",
      "2025-02-20:\t((22913.15 - 22932.90) / 22932.90) * 100 = -0.0861%\n",
      "2025-02-21:\t((22795.90 - 22913.15) / 22913.15) * 100 = -0.5117%\n",
      "2025-02-24:\t((22553.35 - 22795.90) / 22795.90) * 100 = -1.0640%\n",
      "2025-02-25:\t((22547.55 - 22553.35) / 22553.35) * 100 = -0.0257%\n",
      "2025-02-27:\t((22545.05 - 22547.55) / 22547.55) * 100 = -0.0111%\n",
      "2025-02-28:\t((22124.70 - 22545.05) / 22545.05) * 100 = -1.8645%\n",
      "2025-03-03:\t((22119.30 - 22124.70) / 22124.70) * 100 = -0.0244%\n",
      "2025-03-04:\t((22082.65 - 22119.30) / 22119.30) * 100 = -0.1657%\n",
      "2025-03-05:\t((22337.30 - 22082.65) / 22082.65) * 100 = 1.1532%\n",
      "2025-03-06:\t((22544.70 - 22337.30) / 22337.30) * 100 = 0.9285%\n",
      "2025-03-07:\t((22552.50 - 22544.70) / 22544.70) * 100 = 0.0346%\n",
      "2025-03-10:\t((22460.30 - 22552.50) / 22552.50) * 100 = -0.4088%\n",
      "2025-03-11:\t((22497.90 - 22460.30) / 22460.30) * 100 = 0.1674%\n",
      "2025-03-12:\t((22470.50 - 22497.90) / 22497.90) * 100 = -0.1218%\n",
      "2025-03-13:\t((22397.20 - 22470.50) / 22470.50) * 100 = -0.3262%\n",
      "2025-03-17:\t((22508.75 - 22397.20) / 22397.20) * 100 = 0.4981%\n",
      "2025-03-18:\t((22834.30 - 22508.75) / 22508.75) * 100 = 1.4463%\n",
      "2025-03-19:\t((22907.60 - 22834.30) / 22834.30) * 100 = 0.3210%\n",
      "2025-03-20:\t((23190.65 - 22907.60) / 22907.60) * 100 = 1.2356%\n",
      "2025-03-21:\t((23350.40 - 23190.65) / 23190.65) * 100 = 0.6889%\n",
      "2025-03-24:\t((23658.35 - 23350.40) / 23350.40) * 100 = 1.3188%\n",
      "2025-03-25:\t((23668.65 - 23658.35) / 23658.35) * 100 = 0.0435%\n",
      "2025-03-26:\t((23486.85 - 23668.65) / 23668.65) * 100 = -0.7681%\n",
      "2025-03-27:\t((23591.95 - 23486.85) / 23486.85) * 100 = 0.4475%\n",
      "2025-03-28:\t((23519.35 - 23591.95) / 23591.95) * 100 = -0.3077%\n",
      "2025-04-01:\t((23165.70 - 23519.35) / 23519.35) * 100 = -1.5037%\n",
      "2025-04-02:\t((23332.35 - 23165.70) / 23165.70) * 100 = 0.7194%\n",
      "2025-04-03:\t((23250.10 - 23332.35) / 23332.35) * 100 = -0.3525%\n",
      "2025-04-04:\t((22904.45 - 23250.10) / 23250.10) * 100 = -1.4867%\n",
      "2025-04-07:\t((22161.60 - 22904.45) / 22904.45) * 100 = -3.2433%\n",
      "2025-04-08:\t((22535.85 - 22161.60) / 22161.60) * 100 = 1.6887%\n",
      "2025-04-09:\t((22399.15 - 22535.85) / 22535.85) * 100 = -0.6066%\n",
      "2025-04-11:\t((22828.55 - 22399.15) / 22399.15) * 100 = 1.9170%\n",
      "2025-04-15:\t((23328.55 - 22828.55) / 22828.55) * 100 = 2.1902%\n",
      "2025-04-16:\t((23437.20 - 23328.55) / 23328.55) * 100 = 0.4657%\n",
      "2025-04-17:\t((23851.65 - 23437.20) / 23437.20) * 100 = 1.7683%\n",
      "2025-04-21:\t((24125.55 - 23851.65) / 23851.65) * 100 = 1.1483%\n",
      "2025-04-22:\t((24167.25 - 24125.55) / 24125.55) * 100 = 0.1728%\n",
      "2025-04-23:\t((24328.95 - 24167.25) / 24167.25) * 100 = 0.6691%\n",
      "2025-04-24:\t((24246.70 - 24328.95) / 24328.95) * 100 = -0.3381%\n",
      "2025-04-25:\t((24039.35 - 24246.70) / 24246.70) * 100 = -0.8552%\n",
      "2025-04-28:\t((24328.50 - 24039.35) / 24039.35) * 100 = 1.2028%\n",
      "2025-04-29:\t((24335.95 - 24328.50) / 24328.50) * 100 = 0.0306%\n",
      "2025-04-30:\t((24334.20 - 24335.95) / 24335.95) * 100 = -0.0072%\n",
      "2025-05-02:\t((24346.70 - 24334.20) / 24334.20) * 100 = 0.0514%\n",
      "2025-05-05:\t((24461.15 - 24346.70) / 24346.70) * 100 = 0.4701%\n",
      "2025-05-06:\t((24379.60 - 24461.15) / 24461.15) * 100 = -0.3334%\n",
      "2025-05-07:\t((24414.40 - 24379.60) / 24379.60) * 100 = 0.1427%\n",
      "2025-05-08:\t((24273.80 - 24414.40) / 24414.40) * 100 = -0.5759%\n",
      "2025-05-09:\t((24008.00 - 24273.80) / 24273.80) * 100 = -1.0950%\n",
      "2025-05-12:\t((24924.70 - 24008.00) / 24008.00) * 100 = 3.8183%\n",
      "2025-05-13:\t((24578.35 - 24924.70) / 24924.70) * 100 = -1.3896%\n",
      "2025-05-14:\t((24666.90 - 24578.35) / 24578.35) * 100 = 0.3603%\n",
      "2025-05-15:\t((25062.10 - 24666.90) / 24666.90) * 100 = 1.6021%\n",
      "2025-05-16:\t((25019.80 - 25062.10) / 25062.10) * 100 = -0.1688%\n",
      "2025-05-19:\t((24945.45 - 25019.80) / 25019.80) * 100 = -0.2972%\n",
      "2025-05-20:\t((24683.90 - 24945.45) / 24945.45) * 100 = -1.0485%\n",
      "2025-05-21:\t((24813.45 - 24683.90) / 24683.90) * 100 = 0.5248%\n",
      "2025-05-22:\t((24609.70 - 24813.45) / 24813.45) * 100 = -0.8211%\n",
      "2025-05-23:\t((24853.15 - 24609.70) / 24609.70) * 100 = 0.9892%\n",
      "Mean:  0.052595\n",
      "variance:  1.008652\n",
      "dailyVolatility:  1.004317\n",
      "annualizedVolatility:  15.943034\n",
      "spot:  24853.15\n",
      "Annualized Historical Volatility (%): 15.9430%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_volatility(dates,closing_prices):\n",
    "    if len(closing_prices) < 2:\n",
    "        raise ValueError(\"At least two closing prices are required.\")\n",
    "\n",
    "    percentage_returns = []\n",
    "\n",
    "    print(\"Daily Percentage Returns with Calculation Steps:\\n\")\n",
    "    # # Calculate daily percentage returns\n",
    "    # percentage_returns = [\n",
    "    #     ((closing_prices[i] - closing_prices[i - 1]) / closing_prices[i - 1]) * 100\n",
    "    #     for i in range(1, len(closing_prices))\n",
    "    # ]\n",
    "    for i in range(1, len(closing_prices)):\n",
    "        today_price = closing_prices[i]\n",
    "        yesterday_price = closing_prices[i - 1]\n",
    "        pct_return = ((today_price - yesterday_price) / yesterday_price) * 100\n",
    "        percentage_returns.append(pct_return)\n",
    "\n",
    "        # Print date, formula and result\n",
    "        print(f\"{dates[i].date()}:\\t(({today_price:.2f} - {yesterday_price:.2f}) / {yesterday_price:.2f}) * 100 = {pct_return:.4f}%\")\n",
    "\n",
    "    # print(\"LN\")\n",
    "    # for r in percentage_returns:\n",
    "    #     print(r)\n",
    "\n",
    "    # Calculate mean\n",
    "    mean = np.mean(percentage_returns)\n",
    "    print(f\"Mean:  {mean:.6f}\")\n",
    "\n",
    "    # Calculate variance (sample variance)\n",
    "    variance = np.var(percentage_returns, ddof=1)\n",
    "    print(f\"variance:  {variance:.6f}\")\n",
    "\n",
    "    # Daily standard deviation (volatility)\n",
    "    daily_volatility = np.sqrt(variance)\n",
    "    print(f\"dailyVolatility:  {daily_volatility:.6f}\")\n",
    "\n",
    "    # Annualized volatility\n",
    "    annualized_volatility = daily_volatility * np.sqrt(252)\n",
    "    print(f\"annualizedVolatility:  {annualized_volatility:.6f}\")\n",
    "\n",
    "    #last date close price i.e spot of the symbol\n",
    "    spot = closing_prices[-1]\n",
    "    print(f\"spot:  {spot:.2f}\")\n",
    "    return annualized_volatility \n",
    "\n",
    "# Example usage\n",
    "# closing_prices = [\n",
    "#     558.77, 570.9, 576.85, 551.05, 557.05,\n",
    "#     550.75, 544.4, 536.0, 548.65, 549.55,\n",
    "#     551.4, 552.65, 548.05, 542.95\n",
    "# ]\n",
    "closing_prices = df[\"close\"].tolist()\n",
    "dates =df.index.tolist()\n",
    "\n",
    "try:\n",
    "    volatility = calculate_volatility(dates,closing_prices)\n",
    "    print(f\"Annualized Historical Volatility (%): {volatility:.4f}%\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead3160",
   "metadata": {},
   "source": [
    "Fetching the SPOT of the symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25b17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market is closed: Weekend.\n",
      "Cannot fetch live spot price as the market is closed.\n",
      "Please try running this script during NSE market hours (Mon-Fri, 9:15 AM - 3:30 PM IST).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from fyers_apiv3 import fyersModel\n",
    "import json\n",
    "from datetime import datetime, time\n",
    "import pytz\n",
    "\n",
    "def get_symbol_spot_price(client_id: str, access_token: str, symbol: str) -> float | None:\n",
    "    \"\"\"\n",
    "    Fetches the current spot price (LTP) for a given symbol from Fyers.\n",
    "\n",
    "    Args:\n",
    "        client_id (str): Your Fyers API client ID.\n",
    "        access_token (str): Your Fyers API access token.\n",
    "        symbol (str): The Fyers symbol for which to fetch the spot price (e.g., \"NSE:RELIANCE-EQ\").\n",
    "\n",
    "    Returns:\n",
    "        float | None: The Last Traded Price (LTP) of the symbol if successful, otherwise None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fyers = fyersModel.FyersModel(client_id=client_id, is_async=False, token=access_token, log_path=\"\")\n",
    "\n",
    "        data = {\"symbols\": symbol}\n",
    "        response = fyers.quotes(data=data)\n",
    "\n",
    "        if response and response.get(\"code\") == 200 and response.get(\"s\") == \"ok\":\n",
    "            symbol_data = response.get(\"d\")\n",
    "            if symbol_data:\n",
    "                for item in symbol_data:\n",
    "                    if item.get(\"symbol\") == symbol:\n",
    "                        # Extracting LTP, checking for common keys Fyers uses\n",
    "                        # 'lp' (Last Price) is the most common and direct\n",
    "                        # 'v' (value) might contain 'lp' or other details\n",
    "                        ltp = item.get(\"lp\")  # Direct Last Price\n",
    "                        if ltp is None:\n",
    "                            # If 'lp' is not directly present, check within 'v'\n",
    "                            ltp_from_v = item.get(\"v\", {}).get(\"lp\")\n",
    "                            if ltp_from_v is not None:\n",
    "                                print(f\"Found LTP for {symbol} under 'v.lp': {ltp_from_v}\")\n",
    "                                return ltp_from_v\n",
    "                            else:\n",
    "                                print(f\"Warning: 'lp' or 'v.lp' not found for symbol '{symbol}' in response item.\")\n",
    "                                print(f\"Full item data for '{symbol}': {json.dumps(item, indent=2)}\")\n",
    "                        else:\n",
    "                            print(f\"Found LTP for {symbol} under 'lp': {ltp}\")\n",
    "                            return ltp\n",
    "                print(f\"Error: Symbol '{symbol}' not found in the 'd' list of the Fyers API response.\")\n",
    "                print(f\"Full Fyers API response for debugging: {json.dumps(response, indent=2)}\")\n",
    "                return None\n",
    "            else:\n",
    "                print(\"Error: 'd' (symbol data) list is empty in the Fyers API response.\")\n",
    "                print(f\"Full Fyers API response for debugging: {json.dumps(response, indent=2)}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Error fetching quotes from Fyers API. Response: {json.dumps(response, indent=2)}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def is_nse_market_open():\n",
    "    \"\"\"\n",
    "    Checks if NSE market is currently open.\n",
    "    NSE trading hours (approx): Monday-Friday, 9:15 AM to 3:30 PM IST.\n",
    "    \"\"\"\n",
    "    india_tz = pytz.timezone('Asia/Kolkata')\n",
    "    now = datetime.now(india_tz)\n",
    "\n",
    "    # Check if it's a weekday (Monday=0, Sunday=6)\n",
    "    if now.weekday() >= 5:  # Saturday or Sunday\n",
    "        print(\"Market is closed: Weekend.\")\n",
    "        return False\n",
    "\n",
    "    market_open_time = time(9, 15)  # 9:15 AM IST\n",
    "    market_close_time = time(15, 30) # 3:30 PM IST\n",
    "\n",
    "    if market_open_time <= now.time() <= market_close_time:\n",
    "        print(\"Market is currently open.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Market is closed: Outside trading hours (9:15 AM - 3:30 PM IST). Current time: {now.strftime('%H:%M:%S IST')}\")\n",
    "        return False\n",
    "\n",
    "# --- How to use the function ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual Fyers Client ID and Access Token\n",
    "    your_client_id = \"FYZT8L00T9-100\"\n",
    "    your_access_token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsiZDoxIiwiZDoyIiwieDowIiwieDoxIiwieDoyIl0sImF0X2hhc2giOiJnQUFBQUFCb01abUlvdjlMVmdlUUVQU28xU3FnTXpXUXdaSGo0U3ZudzRUQTE4dExDd0RKa091SEJBZjBtS3JzR1FTVXhjeEY5VWJkbzU0cHFSNHloSlNxdnNONzNBQkhDTzZ5Zl9pUzJ6TVRrbWRWQjEzR19Zcz0iLCJkaXNwbGF5X25hbWUiOiIiLCJvbXMiOiJLMSIsImhzbV9rZXkiOiIzNzJmNjg5NTlmYWQ2NDBkOGEyMmQ3NTEzMWU3ODk0ZjE3MDViYWU5MzNkNjYzMzE3MjY5NjNmZiIsImlzRGRwaUVuYWJsZWQiOiJOIiwiaXNNdGZFbmFibGVkIjoiTiIsImZ5X2lkIjoiWUE0NzM3MyIsImFwcFR5cGUiOjEwMCwiZXhwIjoxNzQ4MTMzMDAwLCJpYXQiOjE3NDgwODEwMzIsImlzcyI6ImFwaS5meWVycy5pbiIsIm5iZiI6MTc0ODA4MTAzMiwic3ViIjoiYWNjZXNzX3Rva2VuIn0.g7Dnnk57DGYCNmO4X2SokV9-LMh7JPXj4YGERbFDme8\" # This token is likely expired or invalid if used outside its short validity period.\n",
    "\n",
    "    # Check if market is open before trying to fetch live data\n",
    "    if not is_nse_market_open():\n",
    "        print(\"Cannot fetch live spot price as the market is closed.\")\n",
    "        # If market is closed, the API might not return live LTP or might return\n",
    "        # old data or an empty 'd' array. This is a common reason for your error.\n",
    "        print(\"Please try running this script during NSE market hours (Mon-Fri, 9:15 AM - 3:30 PM IST).\")\n",
    "    else:\n",
    "        # Example symbols\n",
    "        symbol_reliance = \"NSE:RELIANCE-EQ\"\n",
    "        symbol_nifty = \"NSE:NIFTY50-INDEX\"\n",
    "        symbol_invalid = \"NSE:INVALIDSYMBOL-EQ\" # Example of an invalid symbol\n",
    "\n",
    "        print(\"\\nAttempting to fetch spot prices:\")\n",
    "\n",
    "        # Fetch spot price for Reliance\n",
    "        print(f\"\\n--- Fetching {symbol_reliance} ---\")\n",
    "        reliance_ltp = get_symbol_spot_price(your_client_id, your_access_token, symbol_reliance)\n",
    "        if reliance_ltp is not None:\n",
    "            print(f\"Current Spot Price of {symbol_reliance}: {reliance_ltp}\")\n",
    "        else:\n",
    "            print(f\"Could not fetch spot price for {symbol_reliance}\")\n",
    "\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        # Fetch spot price for Nifty 50 Index\n",
    "        print(f\"\\n--- Fetching {symbol_nifty} ---\")\n",
    "        nifty_ltp = get_symbol_spot_price(your_client_id, your_access_token, symbol_nifty)\n",
    "        if nifty_ltp is not None:\n",
    "            print(f\"Current Spot Price of {symbol_nifty}: {nifty_ltp}\")\n",
    "        else:\n",
    "            print(f\"Could not fetch spot price for {symbol_nifty}\")\n",
    "\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        # Fetch spot price for an invalid symbol\n",
    "        print(f\"\\n--- Fetching {symbol_invalid} (expected to fail) ---\")\n",
    "        invalid_ltp = get_symbol_spot_price(your_client_id, your_access_token, symbol_invalid)\n",
    "        if invalid_ltp is not None:\n",
    "            print(f\"Current Spot Price of {symbol_invalid}: {invalid_ltp}\")\n",
    "        else:\n",
    "            print(f\"Could not fetch spot price for {symbol_invalid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5068a3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 09:08:07,200 - INFO - Fetching NIFTY spot from Groww API: https://groww.in/v1/api/stocks_data/v1/accord_points/exchange/NSE/segment/CASH/latest_indices_ohlc/NIFTY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current NIFTY 50 Spot LTP (from Groww API): 24968.4\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Configure logging for better output (optional, but good practice)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_nifty_spot_ltp_sync() -> float | None:\n",
    "    \"\"\"\n",
    "    Fetches the Last Traded Price (LTP) for NIFTY 50 from Groww's API synchronously.\n",
    "\n",
    "    Returns:\n",
    "        float | None: The LTP of NIFTY 50 if successful, otherwise None.\n",
    "    \"\"\"\n",
    "    # Groww API endpoint for NIFTY 50\n",
    "    full_url = \"https://groww.in/v1/api/stocks_data/v1/accord_points/exchange/NSE/segment/CASH/latest_indices_ohlc/NIFTY\"\n",
    "\n",
    "    # Mimic browser headers to avoid potential blocking\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36 Edg/97.0.1072.55\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Referer\": \"https://groww.in/indices/nifty-50\", # Referer for NIFTY 50 page\n",
    "        \"sec-ch-ua\": '\"Not A(Brand\";v=\"8\", \"Chromium\";v=\"97\", \"Microsoft Edge\";v=\"97\"',\n",
    "        \"sec-ch-ua-mobile\": \"?0\",\n",
    "        \"sec-ch-ua-platform\": '\"Windows\"',\n",
    "        \"sec-fetch-dest\": \"empty\",\n",
    "        \"sec-fetch-mode\": \"cors\",\n",
    "        \"sec-fetch-site\": \"same-origin\"\n",
    "    }\n",
    "\n",
    "    timeout = 10 # seconds\n",
    "\n",
    "    logger.info(f\"Fetching NIFTY spot from Groww API: {full_url}\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(full_url, headers=headers, timeout=timeout)\n",
    "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        # Log the full response for debugging (optional)\n",
    "        logger.debug(f\"Full Groww API response: {json.dumps(data, indent=2)}\")\n",
    "\n",
    "        # Extract the LTP (Last Traded Price)\n",
    "        # The response has both 'close' and 'value'. 'value' is typically the most current.\n",
    "        ltp = data.get(\"value\")\n",
    "        if ltp is None:\n",
    "            ltp = data.get(\"close\") # Fallback to 'close' if 'value' is not present\n",
    "\n",
    "        if ltp is not None:\n",
    "            try:\n",
    "                return float(ltp)\n",
    "            except ValueError:\n",
    "                logger.error(f\"Could not convert LTP '{ltp}' to float.\")\n",
    "                return None\n",
    "        else:\n",
    "            logger.error(f\"Neither 'value' nor 'close' field found in Groww API response for NIFTY.\")\n",
    "            return None\n",
    "\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        logger.error(f\"HTTP Error occurred: {errh} - Response: {errh.response.text}\")\n",
    "        return None\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        logger.error(f\"Error Connecting: {errc}\")\n",
    "        return None\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        logger.error(f\"Timeout Error: {errt}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        logger.error(f\"Something went wrong with the request: {err}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Failed to parse JSON response: {e}. Response text: {response.text}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- How to use the function ---\n",
    "if __name__ == \"__main__\":\n",
    "    nifty_spot = get_nifty_spot_ltp_sync()\n",
    "\n",
    "    if nifty_spot is not None:\n",
    "        print(f\"Current NIFTY 50 Spot LTP (from Groww API): {nifty_spot}\")\n",
    "    else:\n",
    "        print(\"Failed to fetch NIFTY 50 Spot LTP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63b77866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'calculation_date': '2025-02-01', 'window_start': '2024-02-01', 'window_end': '2025-01-31', 'trading_days': 250}\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta, datetime\n",
    "\n",
    "\n",
    "def calculate_rolling_volatility(df: pd.DataFrame, calc_date: datetime) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate volatility for a 12-month window ending on calc_date\n",
    "    \"\"\"\n",
    "    # Define the 12-month window\n",
    "    window_end = calc_date - timedelta(days=1)\n",
    "    window_start =  calc_date - pd.DateOffset(years=1)\n",
    "    \n",
    "    # Get data for this window\n",
    "    window_data = df[window_start:window_end]\n",
    "    \n",
    "    if window_data.empty:\n",
    "        raise ValueError(f\"No data found for window {window_start} to {window_end}\")\n",
    "\n",
    "    # Calculate returns and volatility using existing function\n",
    "    closing_prices = window_data['close'].tolist()\n",
    "    dates = window_data.index.tolist()\n",
    "    \n",
    "    #result = calculate_volatility(dates, closing_prices)\n",
    "    \n",
    "    return {\n",
    "        \"calculation_date\": calc_date.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_start\": window_start.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_end\": window_end.strftime(\"%Y-%m-%d\"),\n",
    "        \"trading_days\": len(window_data),\n",
    "        #\"volatility_stats\": result\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "calc_date = \"2025-02-01\"\n",
    "calc_date = datetime.strptime(calc_date, \"%Y-%m-%d\")  # Convert string to datetime\n",
    "volatility_stats = calculate_rolling_volatility(df, calc_date)\n",
    "print(volatility_stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
